{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyseinfrastruktur v5 – Demo Notebook\n",
    "\n",
    "**Theoriegeleitete qualitative Interviewanalyse mit Meta-Frame-Architektur**\n",
    "\n",
    "Dieses Notebook demonstriert die vollständige Analyse-Pipeline:\n",
    "1. **Modul A** – Narrative Struktur (Schütze, Ricoeur)\n",
    "2. **Modul B** – Subjektpositionierung (Bamberg, Lucius-Hoene)\n",
    "3. **Modul C** – Diskursive Rahmung mit Meta-Frames (Foucault, Goffman, Entman)\n",
    "4. **Modul D** – Affektive Dimension (Ahmed, Massumi)\n",
    "5. **JusticeAnalyzer** – (Un)Gerechtigkeits-Spannungsprofile\n",
    "\n",
    "### Architektur\n",
    "\n",
    "```\n",
    "framebook_v3.1.yaml          ← Meta-Frames (universell, themenunabhängig)\n",
    "overlays/\n",
    "  housing_lux.yaml           ← Projektspezifische Erweiterung (optional)\n",
    "```\n",
    "\n",
    "**Zwei-Ebenen-Modell:**\n",
    "- Ebene 1: 10 Meta-Frames + 7 Meta-Topoi (theoriegeleitet, nie anpassen)\n",
    "- Ebene 2: Themen-Overlays (optional, pro Projekt zuschaltbar)\n",
    "\n",
    "### Voraussetzungen\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate analyseinfrastruktur\n",
    "python scripts/setup_nltk.py\n",
    "python -m spacy download de_core_news_sm\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Infrastruktur laden\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys, os\n",
    "INFRA_ROOT = os.path.abspath('..')\n",
    "if INFRA_ROOT not in sys.path:\n",
    "    sys.path.insert(0, INFRA_ROOT)\n",
    "\n",
    "from core.datamodel import Corpus, Document\n",
    "from core.language import LanguageGate\n",
    "from core.framebook import Framebook\n",
    "from core.integration import Integrator\n",
    "from core.justice import JusticeAnalyzer\n",
    "from core.export import export_all\n",
    "from modules import ModulNarrativ, ModulPosition, ModulDiskurs, ModulAffekt\n",
    "from turn_splitter import split_long_turns\n",
    "from diagnose import run_diagnose\n",
    "\n",
    "print('✅ Infrastruktur geladen.')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Einstellungen\n",
    "\n",
    "Alle projektspezifischen Parameter an einer Stelle.\n",
    "Für ein neues Interview: nur diese Zelle anpassen.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Projekt-Einstellungen ──────────────────────────────\n",
    "SPRACHE           = 'en'           # Sprache des Transkripts\n",
    "TRANSKRIPT_DATEI  = '../transkripte/Example Interview Transcript.txt'\n",
    "INTERVIEWER       = {\"Interviewer\"} # Name(n) der Interviewer-Sprecher\n",
    "FRAMEBOOK_PFAD    = '../config/framebook_v3.1.yaml'\n",
    "OVERLAY_PFAD      = '../overlays/housing_lux.yaml'  # None = nur Meta-Frames\n",
    "SPLIT_MAX_CHARS   = 800            # Max. Zeichen pro Turn nach Splitting\n",
    "DOC_ID            = 'interview_01' # Dokumenten-ID\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Analyse ausführen\n",
    "\n",
    "Diese Zelle führt die komplette Pipeline in korrekter Reihenfolge aus:\n",
    "Framebook → Document → Turn-Splitting → Module A–D → Diagnose → Integrator → Justice\n",
    "\n",
    "**Nach Kernel-Restart:** Zellen 1–3 ausführen, dann unten inspizieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ══════════════════════════════════════════════════════\n",
    "#  MASTER-START: Komplette Analyse in korrekter Reihenfolge\n",
    "# ══════════════════════════════════════════════════════\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Framebook + LanguageGate\n",
    "fb = Framebook(FRAMEBOOK_PFAD, overlay=OVERLAY_PFAD)\n",
    "gate = LanguageGate(SPRACHE)\n",
    "\n",
    "print(f'Framebook: {fb}')\n",
    "for k, v in fb.summary().items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "# 2) Document bauen\n",
    "text = Path(TRANSKRIPT_DATEI).read_text(encoding='utf-8')\n",
    "doc = Document.from_text(text, doc_id=DOC_ID, language=SPRACHE)\n",
    "\n",
    "# Befragte-Turns definieren\n",
    "befragte = [t for t in doc.turns if getattr(t, 'sprecher', 'UNKNOWN') not in INTERVIEWER]\n",
    "doc.get_befragte_turns = lambda: befragte\n",
    "print(f'\\nTurns: {len(doc.turns)} (Befragte: {len(befragte)})')\n",
    "\n",
    "# 3) Turn-Splitting (VOR Analyse!)\n",
    "split_long_turns(doc, interviewer=INTERVIEWER, max_chars=SPLIT_MAX_CHARS)\n",
    "\n",
    "# 4) Module initialisieren + Analyse\n",
    "mod_a = ModulNarrativ(gate, fb.textsorten, fb.prozessstrukturen)\n",
    "mod_b = ModulPosition(gate, fb.pronomen, fb.agency)\n",
    "mod_c = ModulDiskurs(gate, fb.frames, fb.topoi, fb.frame_spannungen,\n",
    "                     fb.frame_priorities, fb.frame_conflicts)\n",
    "mod_d = ModulAffekt(gate, fb.affekt_dimensionen)\n",
    "module = {'A': mod_a, 'B': mod_b, 'C': mod_c, 'D': mod_d}\n",
    "\n",
    "doc.annotations = []\n",
    "print('\\nAnalyse...')\n",
    "for name, mod in module.items():\n",
    "    n = mod.analyse(doc)\n",
    "    print(f'  Modul {name} ({mod.name}): {n} Annotations')\n",
    "print(f'Gesamt: {len(doc.annotations)}')\n",
    "\n",
    "# 5) Diagnose\n",
    "report = run_diagnose(doc, module)\n",
    "\n",
    "# 6) Integrator\n",
    "integrator = Integrator(doc, mod_a, mod_b, mod_c, mod_d)\n",
    "\n",
    "# 7) JusticeAnalyzer\n",
    "ja = JusticeAnalyzer(doc, mod_b, mod_c, mod_d,\n",
    "                     fb.frame_priorities, fb.frame_conflicts,\n",
    "                     framebook=fb)\n",
    "\n",
    "print('\\n✅ Analyse abgeschlossen.')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Integrierter Bericht\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "integrator.print_bericht()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. (Un)Gerechtigkeits-Analyse\n",
    "\n",
    "Berechnet Spannungsprofile aus dem Zusammenspiel der Module B (Agency),\n",
    "C (Frames) und D (Affekt). Soziale (Un)Gerechtigkeit wird modelliert als\n",
    "Relation zwischen Anspruchsframes (A) und Strukturframes (S).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ja.print_profil()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Einzelmodule inspizieren\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modul A: Narrative Struktur\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== A: Textsorten-Verlauf ===')\n",
    "for row in mod_a.zusammenfassung(doc):\n",
    "    ps = f' → {row[\"prozessstrukturen\"]}' if row['prozessstrukturen'] != '-' else ''\n",
    "    print(f'  Turn {row[\"turn_id\"]}: {row[\"sequenz_kurz\"]}  |  {row[\"sequenz\"]}{ps}')\n",
    "\n",
    "print('\\n=== A: Wendepunkte ===')\n",
    "for wp in mod_a.wendepunkt_kandidaten(doc):\n",
    "    print(f'  Turn {wp[\"turn_id\"]} (Score: {wp[\"score\"]}): {wp[\"reasons\"]}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modul B: Subjektpositionierung\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== B: Agency ===')\n",
    "for row in mod_b.zusammenfassung(doc):\n",
    "    print(f'  Turn {row[\"turn_id\"]}: {row[\"dominant_agency\"]} ({row[\"agency_dichte\"]}%) | {row[\"pronomen\"]}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modul C: Diskursive Rahmung\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== C: Frames (Raw → Adjusted → Dominant) ===')\n",
    "for row in mod_c.zusammenfassung(doc):\n",
    "    if row['frames']:\n",
    "        raw = row['frames']\n",
    "        adj = row.get('frames_adjusted', raw)\n",
    "        dom = row['dominant_frame']\n",
    "        \n",
    "        diffs = []\n",
    "        for f in raw:\n",
    "            r = raw[f]\n",
    "            a = adj.get(f, r)\n",
    "            if isinstance(a, float) and a < r:\n",
    "                diffs.append(f'{f}: {r}→{a:.1f}')\n",
    "        \n",
    "        print(f'  Turn {row[\"turn_id\"]}: {raw}')\n",
    "        if diffs:\n",
    "            print(f'    ⚖ Adjusted: {diffs}')\n",
    "        print(f'    ★ Dominant: {dom}')\n",
    "\n",
    "print('\\n=== C: Gesamt-Verteilung (Raw vs. Adjusted) ===')\n",
    "from collections import Counter\n",
    "raw_total = Counter()\n",
    "adj_total = Counter()\n",
    "for row in mod_c.zusammenfassung(doc):\n",
    "    for f, c in row['frames'].items():\n",
    "        raw_total[f] += c\n",
    "    for f, c in row.get('frames_adjusted', row['frames']).items():\n",
    "        adj_total[f] += c if isinstance(c, (int, float)) else c\n",
    "\n",
    "total_raw = sum(raw_total.values())\n",
    "total_adj = sum(adj_total.values())\n",
    "print(f'{\"Frame\":<35} {\"Raw\":>5} {\"Raw%\":>6} {\"Adj\":>6} {\"Adj%\":>6}  {\"Δ\":>5}')\n",
    "print('─' * 70)\n",
    "for f in sorted(raw_total, key=raw_total.get, reverse=True):\n",
    "    r = raw_total[f]\n",
    "    a = adj_total.get(f, r)\n",
    "    rp = r / total_raw * 100 if total_raw else 0\n",
    "    ap = a / total_adj * 100 if total_adj else 0\n",
    "    delta = ap - rp\n",
    "    marker = ' ▼' if delta < -1 else ' ▲' if delta > 1 else ''\n",
    "    print(f'  {f:<33} {r:>5} {rp:>5.1f}% {a:>6.1f} {ap:>5.1f}%  {delta:>+.1f}{marker}')\n",
    "\n",
    "print('\\n=== C: Claims ===')\n",
    "for c in mod_c.generate_claims(doc):\n",
    "    print(f'  [{c[\"typ\"]}] {c[\"beschreibung\"]}')\n",
    "    print(f'    {c[\"prueffrage\"]}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modul D: Affektive Dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== D: Affektive Verdichtung ===')\n",
    "for s in mod_d.verdichtungsstellen(doc):\n",
    "    print(f'  Turn {s[\"turn_id\"]} (Score: {s[\"score\"]}, Dichte: {s[\"marker_dichte\"]}%): {s[\"reasons\"]}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audit Trail\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== Audit Trail (erste 10 Annotations) ===')\n",
    "for i, a in enumerate(doc.annotations[:10]):\n",
    "    print(f'[{i+1}] {a.modul} | {a.kategorie} | Match: \"{a.matched_text}\" | Regel: {a.regel_id}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Visualisierung\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "vollbericht = integrator.vollbericht()\n",
    "profiles = vollbericht['turn_profile']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1) Affektive Verdichtung\n",
    "tids = [p['turn_id'] for p in profiles]\n",
    "aff = [p['affekt_dichte'] for p in profiles]\n",
    "farben = plt.cm.YlOrRd([d / max(max(aff), 1) for d in aff])\n",
    "axes[0,0].bar(tids, aff, color=farben, edgecolor='gray')\n",
    "axes[0,0].set_title('Affektive Verdichtung')\n",
    "axes[0,0].set_xlabel('Turn')\n",
    "\n",
    "# 2) Annotations pro Modul\n",
    "mcounts = {}\n",
    "for a in doc.annotations:\n",
    "    mcounts[a.modul] = mcounts.get(a.modul, 0) + 1\n",
    "axes[0,1].barh(list(mcounts.keys()), list(mcounts.values()), color='steelblue')\n",
    "axes[0,1].set_title('Annotations pro Modul')\n",
    "\n",
    "# 3) Diskursive Rahmung\n",
    "turn_counts = defaultdict(Counter)\n",
    "for a in doc.annotations:\n",
    "    m = str(getattr(a, \"modul\", \"\"))\n",
    "    if not m.startswith(\"C\"):\n",
    "        continue\n",
    "    cat = getattr(a, \"kategorie\", None)\n",
    "    tid = getattr(a, \"turn_id\", None)\n",
    "    if cat and tid is not None:\n",
    "        turn_counts[int(tid)][str(cat)] += 1\n",
    "\n",
    "verlauf = [{\"turn_id\": tid, **turn_counts[tid]} for tid in sorted(turn_counts.keys())]\n",
    "if verlauf:\n",
    "    df_f = pd.DataFrame(verlauf).set_index('turn_id')\n",
    "    df_num = df_f.select_dtypes(include=\"number\")\n",
    "    if not df_num.empty:\n",
    "        df_num.plot(kind='bar', stacked=True, ax=axes[1,0], colormap='Set2', legend=False)\n",
    "        axes[1,0].set_title('Diskursive Rahmung')\n",
    "        axes[1,0].legend(fontsize=7)\n",
    "else:\n",
    "    axes[1,0].text(0.5, 0.5, 'Keine C-Daten', ha='center', va='center')\n",
    "    axes[1,0].set_title('Diskursive Rahmung')\n",
    "\n",
    "# 4) Justice-Spannungsprofil\n",
    "jp = ja.turn_profiles()\n",
    "justice_turns = [p for p in jp if p['is_justice_site']]\n",
    "if justice_turns:\n",
    "    axes[1,1].barh(\n",
    "        [f'Turn {p[\"turn_id\"]}' for p in sorted(justice_turns, key=lambda x: x['intensity_norm'])],\n",
    "        [p['intensity_norm'] for p in sorted(justice_turns, key=lambda x: x['intensity_norm'])],\n",
    "        color='coral'\n",
    "    )\n",
    "    axes[1,1].set_title('(Un)Gerechtigkeits-Intensität (/1000z)')\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'Keine Justice-Sites', ha='center', va='center')\n",
    "    axes[1,1].set_title('(Un)Gerechtigkeits-Intensität')\n",
    "\n",
    "plt.suptitle(f'{doc.doc_id} – Analyseübersicht', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Export\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "corpus = Corpus(name='projekt')\n",
    "corpus.add(doc)\n",
    "export_all(corpus, module, output_dir='../output')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Batch-Modus (optional)\n",
    "\n",
    "Für mehrere Interviews: Kommentar entfernen und Pfade anpassen.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# import glob\n",
    "# corpus_batch = Corpus(name='batch')\n",
    "# for fp in sorted(glob.glob('../transkripte/*.txt')):\n",
    "#     text = open(fp, 'r', encoding='utf-8').read()\n",
    "#     d = Document.from_text(text, doc_id=os.path.basename(fp).replace('.txt',''), language=SPRACHE)\n",
    "#     split_long_turns(d, interviewer=INTERVIEWER, max_chars=SPLIT_MAX_CHARS)\n",
    "#     d.annotations = []\n",
    "#     for mod in module.values():\n",
    "#         mod.analyse(d)\n",
    "#     corpus_batch.add(d)\n",
    "#     print(f'  {d.doc_id}: {len(d.annotations)} Annotations')\n",
    "# export_all(corpus_batch, module, output_dir='../output')\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}