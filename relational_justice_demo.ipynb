{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Infrastructure v5 – Main Notebook\n",
    "\n",
    "**Theory-driven qualitative interview analysis with Meta-Frame architecture**\n",
    "\n",
    "This notebook runs the full analysis pipeline:\n",
    "1. **Module A** – Narrative Structure (Schütze, Ricoeur)\n",
    "2. **Module B** – Subject Positioning (Bamberg, Lucius-Hoene)\n",
    "3. **Module C** – Discursive Framing with Meta-Frames (Foucault, Goffman, Entman)\n",
    "4. **Module D** – Affective Dimension (Ahmed, Massumi)\n",
    "5. **JusticeAnalyzer** – Social (In)Justice Tension Profiles\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "framebook_v3.1.yaml          ← Meta-Frames (universal, topic-independent)\n",
    "overlays/\n",
    "  housing_lux.yaml           ← Project-specific extension (optional)\n",
    "```\n",
    "\n",
    "**Two-layer model:**\n",
    "- Layer 1: 10 Meta-Frames + 7 Meta-Topoi (theory-driven, never modify)\n",
    "- Layer 2: Topic overlays (optional, per project)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate analyseinfrastruktur\n",
    "python scripts/setup_nltk.py\n",
    "python -m spacy download de_core_news_sm\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load Infrastructure\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys, os\n",
    "INFRA_ROOT = os.path.abspath('..')\n",
    "if INFRA_ROOT not in sys.path:\n",
    "    sys.path.insert(0, INFRA_ROOT)\n",
    "\n",
    "from core.datamodel import Corpus, Document\n",
    "from core.language import LanguageGate\n",
    "from core.framebook import Framebook\n",
    "from core.integration import Integrator\n",
    "from core.justice import JusticeAnalyzer\n",
    "from core.export import export_all\n",
    "from modules import ModulNarrativ, ModulPosition, ModulDiskurs, ModulAffekt\n",
    "from turn_splitter import split_long_turns\n",
    "from diagnose import run_diagnose\n",
    "\n",
    "print('✅ Infrastructure loaded.')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Settings\n",
    "\n",
    "All project-specific parameters in one place.\n",
    "For a new interview: only modify this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Project Settings ───────────────────────────────────\n",
    "LANGUAGE          = 'en'           # Transcript language\n",
    "TRANSCRIPT_FILE   = '../transkripte/Example Interview Transcript.txt'\n",
    "INTERVIEWER       = {\"Interviewer\"} # Interviewer speaker name(s)\n",
    "FRAMEBOOK_PATH    = '../config/framebook_v3.1.yaml'\n",
    "OVERLAY_PATH      = '../overlays/housing_lux.yaml'  # None = Meta-Frames only\n",
    "SPLIT_MAX_CHARS   = 800            # Max characters per turn after splitting\n",
    "DOC_ID            = 'interview_01' # Document ID\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Run Analysis\n",
    "\n",
    "This cell executes the complete pipeline in the correct order:\n",
    "Framebook → Document → Turn-Splitting → Modules A–D → Diagnostics → Integrator → Justice\n",
    "\n",
    "**After kernel restart:** Run cells 1–3, then inspect below.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ══════════════════════════════════════════════════════\n",
    "#  MASTER START: Complete analysis in correct order\n",
    "# ══════════════════════════════════════════════════════\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Framebook + LanguageGate\n",
    "fb = Framebook(FRAMEBOOK_PATH, overlay=OVERLAY_PATH)\n",
    "gate = LanguageGate(LANGUAGE)\n",
    "\n",
    "print(f'Framebook: {fb}')\n",
    "for k, v in fb.summary().items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "# 2) Build document\n",
    "text = Path(TRANSCRIPT_FILE).read_text(encoding='utf-8')\n",
    "doc = Document.from_text(text, doc_id=DOC_ID, language=LANGUAGE)\n",
    "\n",
    "# Define respondent turns\n",
    "respondent = [t for t in doc.turns if getattr(t, 'sprecher', 'UNKNOWN') not in INTERVIEWER]\n",
    "doc.get_befragte_turns = lambda: respondent\n",
    "print(f'\\nTurns: {len(doc.turns)} (Respondent: {len(respondent)})')\n",
    "\n",
    "# 3) Turn splitting (BEFORE analysis!)\n",
    "split_long_turns(doc, interviewer=INTERVIEWER, max_chars=SPLIT_MAX_CHARS)\n",
    "\n",
    "# 4) Initialize modules + run analysis\n",
    "mod_a = ModulNarrativ(gate, fb.textsorten, fb.prozessstrukturen)\n",
    "mod_b = ModulPosition(gate, fb.pronomen, fb.agency)\n",
    "mod_c = ModulDiskurs(gate, fb.frames, fb.topoi, fb.frame_spannungen,\n",
    "                     fb.frame_priorities, fb.frame_conflicts)\n",
    "mod_d = ModulAffekt(gate, fb.affekt_dimensionen)\n",
    "modules = {'A': mod_a, 'B': mod_b, 'C': mod_c, 'D': mod_d}\n",
    "\n",
    "doc.annotations = []\n",
    "print('\\nRunning analysis...')\n",
    "for name, mod in modules.items():\n",
    "    n = mod.analyse(doc)\n",
    "    print(f'  Module {name} ({mod.name}): {n} annotations')\n",
    "print(f'Total: {len(doc.annotations)}')\n",
    "\n",
    "# 5) Diagnostics\n",
    "report = run_diagnose(doc, modules)\n",
    "\n",
    "# 6) Integrator\n",
    "integrator = Integrator(doc, mod_a, mod_b, mod_c, mod_d)\n",
    "\n",
    "# 7) JusticeAnalyzer\n",
    "ja = JusticeAnalyzer(doc, mod_b, mod_c, mod_d,\n",
    "                     fb.frame_priorities, fb.frame_conflicts,\n",
    "                     framebook=fb)\n",
    "\n",
    "print('\\n✅ Analysis complete.')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Integrated Report\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "integrator.print_bericht()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Social (In)Justice Analysis\n",
    "\n",
    "Computes tension profiles from the interplay of Module B (Agency),\n",
    "C (Frames), and D (Affect). Social (in)justice is modeled as the\n",
    "relation between aspiration frames (A) and structural frames (S).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ja.print_profil()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Inspect Individual Modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module A: Narrative Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== A: Text Type Sequence ===')\n",
    "for row in mod_a.zusammenfassung(doc):\n",
    "    ps = f' → {row[\"prozessstrukturen\"]}' if row['prozessstrukturen'] != '-' else ''\n",
    "    print(f'  Turn {row[\"turn_id\"]}: {row[\"sequenz_kurz\"]}  |  {row[\"sequenz\"]}{ps}')\n",
    "\n",
    "print('\\n=== A: Turning Points ===')\n",
    "for wp in mod_a.wendepunkt_kandidaten(doc):\n",
    "    print(f'  Turn {wp[\"turn_id\"]} (Score: {wp[\"score\"]}): {wp[\"reasons\"]}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module B: Subject Positioning\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== B: Agency ===')\n",
    "for row in mod_b.zusammenfassung(doc):\n",
    "    print(f'  Turn {row[\"turn_id\"]}: {row[\"dominant_agency\"]} ({row[\"agency_dichte\"]}%) | {row[\"pronomen\"]}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module C: Discursive Framing\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== C: Frames (Raw → Adjusted → Dominant) ===')\n",
    "for row in mod_c.zusammenfassung(doc):\n",
    "    if row['frames']:\n",
    "        raw = row['frames']\n",
    "        adj = row.get('frames_adjusted', raw)\n",
    "        dom = row['dominant_frame']\n",
    "        \n",
    "        diffs = []\n",
    "        for f in raw:\n",
    "            r = raw[f]\n",
    "            a = adj.get(f, r)\n",
    "            if isinstance(a, float) and a < r:\n",
    "                diffs.append(f'{f}: {r}→{a:.1f}')\n",
    "        \n",
    "        print(f'  Turn {row[\"turn_id\"]}: {raw}')\n",
    "        if diffs:\n",
    "            print(f'    ⚖ Adjusted: {diffs}')\n",
    "        print(f'    ★ Dominant: {dom}')\n",
    "\n",
    "print('\\n=== C: Overall Distribution (Raw vs. Adjusted) ===')\n",
    "from collections import Counter\n",
    "raw_total = Counter()\n",
    "adj_total = Counter()\n",
    "for row in mod_c.zusammenfassung(doc):\n",
    "    for f, c in row['frames'].items():\n",
    "        raw_total[f] += c\n",
    "    for f, c in row.get('frames_adjusted', row['frames']).items():\n",
    "        adj_total[f] += c if isinstance(c, (int, float)) else c\n",
    "\n",
    "total_raw = sum(raw_total.values())\n",
    "total_adj = sum(adj_total.values())\n",
    "print(f'{\"Frame\":<35} {\"Raw\":>5} {\"Raw%\":>6} {\"Adj\":>6} {\"Adj%\":>6}  {\"Δ\":>5}')\n",
    "print('─' * 70)\n",
    "for f in sorted(raw_total, key=raw_total.get, reverse=True):\n",
    "    r = raw_total[f]\n",
    "    a = adj_total.get(f, r)\n",
    "    rp = r / total_raw * 100 if total_raw else 0\n",
    "    ap = a / total_adj * 100 if total_adj else 0\n",
    "    delta = ap - rp\n",
    "    marker = ' ▼' if delta < -1 else ' ▲' if delta > 1 else ''\n",
    "    print(f'  {f:<33} {r:>5} {rp:>5.1f}% {a:>6.1f} {ap:>5.1f}%  {delta:>+.1f}{marker}')\n",
    "\n",
    "print('\\n=== C: Claims ===')\n",
    "for c in mod_c.generate_claims(doc):\n",
    "    print(f'  [{c[\"typ\"]}] {c[\"beschreibung\"]}')\n",
    "    print(f'    {c[\"prueffrage\"]}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module D: Affective Dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== D: Affective Condensation Points ===')\n",
    "for s in mod_d.verdichtungsstellen(doc):\n",
    "    print(f'  Turn {s[\"turn_id\"]} (Score: {s[\"score\"]}, Density: {s[\"marker_dichte\"]}%): {s[\"reasons\"]}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audit Trail\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=== Audit Trail (first 10 annotations) ===')\n",
    "for i, a in enumerate(doc.annotations[:10]):\n",
    "    print(f'[{i+1}] {a.modul} | {a.kategorie} | Match: \"{a.matched_text}\" | Rule: {a.regel_id}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "vollbericht = integrator.vollbericht()\n",
    "profiles = vollbericht['turn_profile']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1) Affective condensation\n",
    "tids = [p['turn_id'] for p in profiles]\n",
    "aff = [p['affekt_dichte'] for p in profiles]\n",
    "colors = plt.cm.YlOrRd([d / max(max(aff), 1) for d in aff])\n",
    "axes[0,0].bar(tids, aff, color=colors, edgecolor='gray')\n",
    "axes[0,0].set_title('Affective Condensation')\n",
    "axes[0,0].set_xlabel('Turn')\n",
    "\n",
    "# 2) Annotations per module\n",
    "mcounts = {}\n",
    "for a in doc.annotations:\n",
    "    mcounts[a.modul] = mcounts.get(a.modul, 0) + 1\n",
    "axes[0,1].barh(list(mcounts.keys()), list(mcounts.values()), color='steelblue')\n",
    "axes[0,1].set_title('Annotations per Module')\n",
    "\n",
    "# 3) Discursive framing\n",
    "turn_counts = defaultdict(Counter)\n",
    "for a in doc.annotations:\n",
    "    m = str(getattr(a, \"modul\", \"\"))\n",
    "    if not m.startswith(\"C\"):\n",
    "        continue\n",
    "    cat = getattr(a, \"kategorie\", None)\n",
    "    tid = getattr(a, \"turn_id\", None)\n",
    "    if cat and tid is not None:\n",
    "        turn_counts[int(tid)][str(cat)] += 1\n",
    "\n",
    "sequence = [{\"turn_id\": tid, **turn_counts[tid]} for tid in sorted(turn_counts.keys())]\n",
    "if sequence:\n",
    "    df_f = pd.DataFrame(sequence).set_index('turn_id')\n",
    "    df_num = df_f.select_dtypes(include=\"number\")\n",
    "    if not df_num.empty:\n",
    "        df_num.plot(kind='bar', stacked=True, ax=axes[1,0], colormap='Set2', legend=False)\n",
    "        axes[1,0].set_title('Discursive Framing')\n",
    "        axes[1,0].legend(fontsize=7)\n",
    "else:\n",
    "    axes[1,0].text(0.5, 0.5, 'No frame data', ha='center', va='center')\n",
    "    axes[1,0].set_title('Discursive Framing')\n",
    "\n",
    "# 4) Justice tension profile\n",
    "jp = ja.turn_profiles()\n",
    "justice_turns = [p for p in jp if p['is_justice_site']]\n",
    "if justice_turns:\n",
    "    axes[1,1].barh(\n",
    "        [f'Turn {p[\"turn_id\"]}' for p in sorted(justice_turns, key=lambda x: x['intensity_norm'])],\n",
    "        [p['intensity_norm'] for p in sorted(justice_turns, key=lambda x: x['intensity_norm'])],\n",
    "        color='coral'\n",
    "    )\n",
    "    axes[1,1].set_title('(In)Justice Tension Intensity (/1000 chars)')\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'No justice sites', ha='center', va='center')\n",
    "    axes[1,1].set_title('(In)Justice Tension Intensity')\n",
    "\n",
    "plt.suptitle(f'{doc.doc_id} – Analysis Overview', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Export\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "corpus = Corpus(name='project')\n",
    "corpus.add(doc)\n",
    "export_all(corpus, modules, output_dir='../output')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Batch Mode (optional)\n",
    "\n",
    "For multiple interviews: uncomment and adjust paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# import glob\n",
    "# corpus_batch = Corpus(name='batch')\n",
    "# for fp in sorted(glob.glob('../transkripte/*.txt')):\n",
    "#     text = open(fp, 'r', encoding='utf-8').read()\n",
    "#     d = Document.from_text(text, doc_id=os.path.basename(fp).replace('.txt',''), language=LANGUAGE)\n",
    "#     split_long_turns(d, interviewer=INTERVIEWER, max_chars=SPLIT_MAX_CHARS)\n",
    "#     d.annotations = []\n",
    "#     for mod in modules.values():\n",
    "#         mod.analyse(d)\n",
    "#     corpus_batch.add(d)\n",
    "#     print(f'  {d.doc_id}: {len(d.annotations)} annotations')\n",
    "# export_all(corpus_batch, modules, output_dir='../output')\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
